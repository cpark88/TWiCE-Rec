{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 25.0,
  "eval_steps": 500,
  "global_step": 100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.25,
      "grad_norm": 0.09824123978614807,
      "learning_rate": 0.0,
      "loss": 1.3993,
      "step": 1
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.09882884472608566,
      "learning_rate": 0.0003333333333333333,
      "loss": 1.3986,
      "step": 2
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.0992368534207344,
      "learning_rate": 0.0006666666666666666,
      "loss": 1.3973,
      "step": 3
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.09933938086032867,
      "learning_rate": 0.001,
      "loss": 1.3946,
      "step": 4
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.10225022584199905,
      "learning_rate": 0.0009997377845227576,
      "loss": 1.381,
      "step": 5
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.10163099318742752,
      "learning_rate": 0.0009989514131188558,
      "loss": 1.376,
      "step": 6
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.10507301986217499,
      "learning_rate": 0.0009976417105833069,
      "loss": 1.3682,
      "step": 7
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.1096281111240387,
      "learning_rate": 0.0009958100506132126,
      "loss": 1.3589,
      "step": 8
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.11044340580701828,
      "learning_rate": 0.0009934583543669453,
      "loss": 1.3431,
      "step": 9
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.1138349175453186,
      "learning_rate": 0.0009905890884491196,
      "loss": 1.3309,
      "step": 10
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.11386478692293167,
      "learning_rate": 0.000987205262323463,
      "loss": 1.3165,
      "step": 11
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.10552026331424713,
      "learning_rate": 0.0009833104251563056,
      "loss": 1.3014,
      "step": 12
    },
    {
      "epoch": 3.25,
      "grad_norm": 0.1026383489370346,
      "learning_rate": 0.0009789086620939935,
      "loss": 1.2803,
      "step": 13
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.09494323283433914,
      "learning_rate": 0.0009740045899781352,
      "loss": 1.2708,
      "step": 14
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.09274208545684814,
      "learning_rate": 0.0009686033525031719,
      "loss": 1.2491,
      "step": 15
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.09096666425466537,
      "learning_rate": 0.0009627106148213521,
      "loss": 1.2375,
      "step": 16
    },
    {
      "epoch": 4.25,
      "grad_norm": 0.08871359378099442,
      "learning_rate": 0.0009563325576007701,
      "loss": 1.2235,
      "step": 17
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.08744445443153381,
      "learning_rate": 0.0009494758705426977,
      "loss": 1.21,
      "step": 18
    },
    {
      "epoch": 4.75,
      "grad_norm": 0.08548077195882797,
      "learning_rate": 0.0009421477453650118,
      "loss": 1.2089,
      "step": 19
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.0854138433933258,
      "learning_rate": 0.0009343558682590756,
      "loss": 1.1844,
      "step": 20
    },
    {
      "epoch": 5.25,
      "grad_norm": 0.082276850938797,
      "learning_rate": 0.0009261084118279846,
      "loss": 1.1713,
      "step": 21
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.0827077180147171,
      "learning_rate": 0.0009174140265146356,
      "loss": 1.1603,
      "step": 22
    },
    {
      "epoch": 5.75,
      "grad_norm": 0.08051788806915283,
      "learning_rate": 0.0009082818315286055,
      "loss": 1.1533,
      "step": 23
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.07982897013425827,
      "learning_rate": 0.0008987214052813603,
      "loss": 1.1456,
      "step": 24
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.07794248312711716,
      "learning_rate": 0.0008887427753398248,
      "loss": 1.1329,
      "step": 25
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.07781802862882614,
      "learning_rate": 0.0008783564079088476,
      "loss": 1.1192,
      "step": 26
    },
    {
      "epoch": 6.75,
      "grad_norm": 0.07755202054977417,
      "learning_rate": 0.0008675731968536002,
      "loss": 1.1264,
      "step": 27
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.07850594073534012,
      "learning_rate": 0.0008564044522734146,
      "loss": 1.1217,
      "step": 28
    },
    {
      "epoch": 7.25,
      "grad_norm": 0.07774975150823593,
      "learning_rate": 0.0008448618886390522,
      "loss": 1.1085,
      "step": 29
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.07873808592557907,
      "learning_rate": 0.0008329576125058406,
      "loss": 1.0994,
      "step": 30
    },
    {
      "epoch": 7.75,
      "grad_norm": 0.07874346524477005,
      "learning_rate": 0.00082070410981557,
      "loss": 1.0924,
      "step": 31
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.0781082808971405,
      "learning_rate": 0.0008081142328004637,
      "loss": 1.0926,
      "step": 32
    },
    {
      "epoch": 8.25,
      "grad_norm": 0.07568774372339249,
      "learning_rate": 0.0007952011865029613,
      "loss": 1.0883,
      "step": 33
    },
    {
      "epoch": 8.5,
      "grad_norm": 0.07594770938158035,
      "learning_rate": 0.0007819785149254532,
      "loss": 1.0914,
      "step": 34
    },
    {
      "epoch": 8.75,
      "grad_norm": 0.0760142132639885,
      "learning_rate": 0.0007684600868244919,
      "loss": 1.0801,
      "step": 35
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.07523045688867569,
      "learning_rate": 0.0007546600811643815,
      "loss": 1.0774,
      "step": 36
    },
    {
      "epoch": 9.25,
      "grad_norm": 0.07593655586242676,
      "learning_rate": 0.0007405929722454026,
      "loss": 1.0653,
      "step": 37
    },
    {
      "epoch": 9.5,
      "grad_norm": 0.07720315456390381,
      "learning_rate": 0.0007262735145222696,
      "loss": 1.0727,
      "step": 38
    },
    {
      "epoch": 9.75,
      "grad_norm": 0.07646580785512924,
      "learning_rate": 0.0007117167271287453,
      "loss": 1.0729,
      "step": 39
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.07602725923061371,
      "learning_rate": 0.0006969378781246436,
      "loss": 1.0648,
      "step": 40
    },
    {
      "epoch": 10.25,
      "grad_norm": 0.07750680297613144,
      "learning_rate": 0.0006819524684817438,
      "loss": 1.0572,
      "step": 41
    },
    {
      "epoch": 10.5,
      "grad_norm": 0.0794747918844223,
      "learning_rate": 0.0006667762158254104,
      "loss": 1.0586,
      "step": 42
    },
    {
      "epoch": 10.75,
      "grad_norm": 0.0779913142323494,
      "learning_rate": 0.0006514250379489753,
      "loss": 1.0569,
      "step": 43
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.07792311161756516,
      "learning_rate": 0.0006359150361181715,
      "loss": 1.0527,
      "step": 44
    },
    {
      "epoch": 11.25,
      "grad_norm": 0.07874048501253128,
      "learning_rate": 0.0006202624781831269,
      "loss": 1.054,
      "step": 45
    },
    {
      "epoch": 11.5,
      "grad_norm": 0.07819399237632751,
      "learning_rate": 0.0006044837815156376,
      "loss": 1.0447,
      "step": 46
    },
    {
      "epoch": 11.75,
      "grad_norm": 0.07954150438308716,
      "learning_rate": 0.0005885954957896114,
      "loss": 1.0423,
      "step": 47
    },
    {
      "epoch": 12.0,
      "grad_norm": 0.07852288335561752,
      "learning_rate": 0.0005726142856227452,
      "loss": 1.0445,
      "step": 48
    },
    {
      "epoch": 12.25,
      "grad_norm": 0.08078444749116898,
      "learning_rate": 0.0005565569130976422,
      "loss": 1.0424,
      "step": 49
    },
    {
      "epoch": 12.5,
      "grad_norm": 0.07917915284633636,
      "learning_rate": 0.0005404402201807021,
      "loss": 1.0426,
      "step": 50
    },
    {
      "epoch": 12.75,
      "grad_norm": 0.07897762209177017,
      "learning_rate": 0.0005242811110572242,
      "loss": 1.0374,
      "step": 51
    },
    {
      "epoch": 13.0,
      "grad_norm": 0.07905296981334686,
      "learning_rate": 0.0005080965344012508,
      "loss": 1.0355,
      "step": 52
    },
    {
      "epoch": 13.25,
      "grad_norm": 0.07937602698802948,
      "learning_rate": 0.0004919034655987492,
      "loss": 1.0308,
      "step": 53
    },
    {
      "epoch": 13.5,
      "grad_norm": 0.07844967395067215,
      "learning_rate": 0.000475718888942776,
      "loss": 1.0342,
      "step": 54
    },
    {
      "epoch": 13.75,
      "grad_norm": 0.07938381284475327,
      "learning_rate": 0.00045955977981929796,
      "loss": 1.0339,
      "step": 55
    },
    {
      "epoch": 14.0,
      "grad_norm": 0.07935386896133423,
      "learning_rate": 0.0004434430869023579,
      "loss": 1.0297,
      "step": 56
    },
    {
      "epoch": 14.25,
      "grad_norm": 0.07981131970882416,
      "learning_rate": 0.000427385714377255,
      "loss": 1.0278,
      "step": 57
    },
    {
      "epoch": 14.5,
      "grad_norm": 0.07984625548124313,
      "learning_rate": 0.00041140450421038864,
      "loss": 1.0244,
      "step": 58
    },
    {
      "epoch": 14.75,
      "grad_norm": 0.08002693951129913,
      "learning_rate": 0.0003955162184843625,
      "loss": 1.0215,
      "step": 59
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.0787164643406868,
      "learning_rate": 0.00037973752181687335,
      "loss": 1.0235,
      "step": 60
    },
    {
      "epoch": 15.25,
      "grad_norm": 0.0821622684597969,
      "learning_rate": 0.00036408496388182855,
      "loss": 1.02,
      "step": 61
    },
    {
      "epoch": 15.5,
      "grad_norm": 0.07981882989406586,
      "learning_rate": 0.0003485749620510247,
      "loss": 1.0275,
      "step": 62
    },
    {
      "epoch": 15.75,
      "grad_norm": 0.08107447624206543,
      "learning_rate": 0.0003332237841745898,
      "loss": 1.0259,
      "step": 63
    },
    {
      "epoch": 16.0,
      "grad_norm": 0.07991167902946472,
      "learning_rate": 0.0003180475315182563,
      "loss": 1.015,
      "step": 64
    },
    {
      "epoch": 16.25,
      "grad_norm": 0.08013611286878586,
      "learning_rate": 0.00030306212187535653,
      "loss": 1.0129,
      "step": 65
    },
    {
      "epoch": 16.5,
      "grad_norm": 0.07964186370372772,
      "learning_rate": 0.0002882832728712551,
      "loss": 1.0142,
      "step": 66
    },
    {
      "epoch": 16.75,
      "grad_norm": 0.08112014830112457,
      "learning_rate": 0.0002737264854777306,
      "loss": 1.0075,
      "step": 67
    },
    {
      "epoch": 17.0,
      "grad_norm": 0.081023670732975,
      "learning_rate": 0.00025940702775459747,
      "loss": 1.0178,
      "step": 68
    },
    {
      "epoch": 17.25,
      "grad_norm": 0.07979284971952438,
      "learning_rate": 0.00024533991883561866,
      "loss": 1.0156,
      "step": 69
    },
    {
      "epoch": 17.5,
      "grad_norm": 0.08274973183870316,
      "learning_rate": 0.0002315399131755081,
      "loss": 1.0105,
      "step": 70
    },
    {
      "epoch": 17.75,
      "grad_norm": 0.08030635863542557,
      "learning_rate": 0.0002180214850745467,
      "loss": 1.0014,
      "step": 71
    },
    {
      "epoch": 18.0,
      "grad_norm": 0.07985159754753113,
      "learning_rate": 0.00020479881349703882,
      "loss": 1.0045,
      "step": 72
    },
    {
      "epoch": 18.25,
      "grad_norm": 0.08213087916374207,
      "learning_rate": 0.00019188576719953633,
      "loss": 1.009,
      "step": 73
    },
    {
      "epoch": 18.5,
      "grad_norm": 0.08104220032691956,
      "learning_rate": 0.00017929589018443015,
      "loss": 1.0107,
      "step": 74
    },
    {
      "epoch": 18.75,
      "grad_norm": 0.0797179788351059,
      "learning_rate": 0.00016704238749415957,
      "loss": 1.0138,
      "step": 75
    },
    {
      "epoch": 19.0,
      "grad_norm": 0.07986217737197876,
      "learning_rate": 0.00015513811136094787,
      "loss": 1.0063,
      "step": 76
    },
    {
      "epoch": 19.25,
      "grad_norm": 0.0814969465136528,
      "learning_rate": 0.00014359554772658552,
      "loss": 1.0126,
      "step": 77
    },
    {
      "epoch": 19.5,
      "grad_norm": 0.0812450647354126,
      "learning_rate": 0.00013242680314639994,
      "loss": 1.0096,
      "step": 78
    },
    {
      "epoch": 19.75,
      "grad_norm": 0.08023814111948013,
      "learning_rate": 0.00012164359209115234,
      "loss": 1.0039,
      "step": 79
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.08048504590988159,
      "learning_rate": 0.00011125722466017545,
      "loss": 1.0065,
      "step": 80
    },
    {
      "epoch": 20.25,
      "grad_norm": 0.08020691573619843,
      "learning_rate": 0.0001012785947186397,
      "loss": 1.0048,
      "step": 81
    },
    {
      "epoch": 20.5,
      "grad_norm": 0.07978226244449615,
      "learning_rate": 9.171816847139447e-05,
      "loss": 1.0017,
      "step": 82
    },
    {
      "epoch": 20.75,
      "grad_norm": 0.0808185562491417,
      "learning_rate": 8.258597348536451e-05,
      "loss": 1.016,
      "step": 83
    },
    {
      "epoch": 21.0,
      "grad_norm": 0.08072435110807419,
      "learning_rate": 7.38915881720154e-05,
      "loss": 1.0094,
      "step": 84
    },
    {
      "epoch": 21.25,
      "grad_norm": 0.08135991543531418,
      "learning_rate": 6.564413174092443e-05,
      "loss": 1.0075,
      "step": 85
    },
    {
      "epoch": 21.5,
      "grad_norm": 0.08065515011548996,
      "learning_rate": 5.785225463498828e-05,
      "loss": 1.0058,
      "step": 86
    },
    {
      "epoch": 21.75,
      "grad_norm": 0.0827701985836029,
      "learning_rate": 5.0524129457302394e-05,
      "loss": 1.0071,
      "step": 87
    },
    {
      "epoch": 22.0,
      "grad_norm": 0.0801258459687233,
      "learning_rate": 4.366744239922998e-05,
      "loss": 0.9965,
      "step": 88
    },
    {
      "epoch": 22.25,
      "grad_norm": 0.08105301856994629,
      "learning_rate": 3.728938517864794e-05,
      "loss": 1.0121,
      "step": 89
    },
    {
      "epoch": 22.5,
      "grad_norm": 0.08225759118795395,
      "learning_rate": 3.1396647496828245e-05,
      "loss": 1.0117,
      "step": 90
    },
    {
      "epoch": 22.75,
      "grad_norm": 0.0811971053481102,
      "learning_rate": 2.5995410021864786e-05,
      "loss": 0.9973,
      "step": 91
    },
    {
      "epoch": 23.0,
      "grad_norm": 0.08154575526714325,
      "learning_rate": 2.109133790600648e-05,
      "loss": 0.9969,
      "step": 92
    },
    {
      "epoch": 23.25,
      "grad_norm": 0.08142342418432236,
      "learning_rate": 1.6689574843694434e-05,
      "loss": 1.0052,
      "step": 93
    },
    {
      "epoch": 23.5,
      "grad_norm": 0.08072111755609512,
      "learning_rate": 1.2794737676536993e-05,
      "loss": 1.0085,
      "step": 94
    },
    {
      "epoch": 23.75,
      "grad_norm": 0.08202555775642395,
      "learning_rate": 9.410911550880474e-06,
      "loss": 1.0035,
      "step": 95
    },
    {
      "epoch": 24.0,
      "grad_norm": 0.08208610117435455,
      "learning_rate": 6.541645633054649e-06,
      "loss": 1.007,
      "step": 96
    },
    {
      "epoch": 24.25,
      "grad_norm": 0.08118802309036255,
      "learning_rate": 4.189949386787462e-06,
      "loss": 1.0056,
      "step": 97
    },
    {
      "epoch": 24.5,
      "grad_norm": 0.08184262365102768,
      "learning_rate": 2.3582894166930268e-06,
      "loss": 1.0068,
      "step": 98
    },
    {
      "epoch": 24.75,
      "grad_norm": 0.08092909306287766,
      "learning_rate": 1.0485868811441758e-06,
      "loss": 1.0002,
      "step": 99
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.08101429790258408,
      "learning_rate": 2.6221547724253336e-07,
      "loss": 1.0033,
      "step": 100
    },
    {
      "epoch": 25.0,
      "step": 100,
      "total_flos": 0.0,
      "train_loss": 1.0951332730054855,
      "train_runtime": 13.4758,
      "train_samples_per_second": 27595.741,
      "train_steps_per_second": 7.421
    }
  ],
  "logging_steps": 1.0,
  "max_steps": 100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 25,
  "save_steps": 20,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2048,
  "trial_name": null,
  "trial_params": null
}
