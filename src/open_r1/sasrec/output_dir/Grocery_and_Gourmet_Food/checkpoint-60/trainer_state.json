{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 20.0,
  "eval_steps": 500,
  "global_step": 60,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.07502208650112152,
      "learning_rate": 0.0,
      "loss": 1.3985,
      "step": 1
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.07581540942192078,
      "learning_rate": 0.0005,
      "loss": 1.3982,
      "step": 2
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.07577677816152573,
      "learning_rate": 0.001,
      "loss": 1.3963,
      "step": 3
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.0750809833407402,
      "learning_rate": 0.0009992667069255619,
      "loss": 1.3886,
      "step": 4
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.0789843499660492,
      "learning_rate": 0.0009970689785771798,
      "loss": 1.3825,
      "step": 5
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.08313781768083572,
      "learning_rate": 0.0009934132612707631,
      "loss": 1.3728,
      "step": 6
    },
    {
      "epoch": 2.3333333333333335,
      "grad_norm": 0.08606291562318802,
      "learning_rate": 0.0009883102778550433,
      "loss": 1.3649,
      "step": 7
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 0.09219999611377716,
      "learning_rate": 0.0009817749962596114,
      "loss": 1.3517,
      "step": 8
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.09807371348142624,
      "learning_rate": 0.0009738265855914012,
      "loss": 1.3373,
      "step": 9
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.09652021527290344,
      "learning_rate": 0.0009644883599083958,
      "loss": 1.3182,
      "step": 10
    },
    {
      "epoch": 3.6666666666666665,
      "grad_norm": 0.09310868382453918,
      "learning_rate": 0.0009537877098354786,
      "loss": 1.3024,
      "step": 11
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.08208836615085602,
      "learning_rate": 0.0009417560222230115,
      "loss": 1.2872,
      "step": 12
    },
    {
      "epoch": 4.333333333333333,
      "grad_norm": 0.07798287272453308,
      "learning_rate": 0.0009284285880837946,
      "loss": 1.2698,
      "step": 13
    },
    {
      "epoch": 4.666666666666667,
      "grad_norm": 0.0746481642127037,
      "learning_rate": 0.0009138444990784454,
      "loss": 1.2577,
      "step": 14
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.07204485684633255,
      "learning_rate": 0.0008980465328528219,
      "loss": 1.2488,
      "step": 15
    },
    {
      "epoch": 5.333333333333333,
      "grad_norm": 0.0696486085653305,
      "learning_rate": 0.0008810810275638182,
      "loss": 1.2407,
      "step": 16
    },
    {
      "epoch": 5.666666666666667,
      "grad_norm": 0.0688217356801033,
      "learning_rate": 0.0008629977459615654,
      "loss": 1.2315,
      "step": 17
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.06561572849750519,
      "learning_rate": 0.0008438497294267117,
      "loss": 1.2163,
      "step": 18
    },
    {
      "epoch": 6.333333333333333,
      "grad_norm": 0.06473970413208008,
      "learning_rate": 0.0008236931423909139,
      "loss": 1.2073,
      "step": 19
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 0.06335938721895218,
      "learning_rate": 0.0008025871075968827,
      "loss": 1.2009,
      "step": 20
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.0620901994407177,
      "learning_rate": 0.0007805935326811913,
      "loss": 1.192,
      "step": 21
    },
    {
      "epoch": 7.333333333333333,
      "grad_norm": 0.061541639268398285,
      "learning_rate": 0.0007577769285885109,
      "loss": 1.1861,
      "step": 22
    },
    {
      "epoch": 7.666666666666667,
      "grad_norm": 0.06147200986742973,
      "learning_rate": 0.0007342042203498951,
      "loss": 1.1787,
      "step": 23
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.06003931909799576,
      "learning_rate": 0.0007099445507801323,
      "loss": 1.1737,
      "step": 24
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 0.05949845165014267,
      "learning_rate": 0.0006850690776699573,
      "loss": 1.1664,
      "step": 25
    },
    {
      "epoch": 8.666666666666666,
      "grad_norm": 0.059983834624290466,
      "learning_rate": 0.00065965076506799,
      "loss": 1.1652,
      "step": 26
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.060103945434093475,
      "learning_rate": 0.0006337641692646106,
      "loss": 1.1543,
      "step": 27
    },
    {
      "epoch": 9.333333333333334,
      "grad_norm": 0.05956808477640152,
      "learning_rate": 0.0006074852201055121,
      "loss": 1.1535,
      "step": 28
    },
    {
      "epoch": 9.666666666666666,
      "grad_norm": 0.06056385487318039,
      "learning_rate": 0.0005808909982763825,
      "loss": 1.1522,
      "step": 29
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.06152120605111122,
      "learning_rate": 0.0005540595092119709,
      "loss": 1.1524,
      "step": 30
    },
    {
      "epoch": 10.333333333333334,
      "grad_norm": 0.06172686442732811,
      "learning_rate": 0.0005270694542927088,
      "loss": 1.148,
      "step": 31
    },
    {
      "epoch": 10.666666666666666,
      "grad_norm": 0.06231291592121124,
      "learning_rate": 0.0005,
      "loss": 1.1437,
      "step": 32
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.06138090789318085,
      "learning_rate": 0.00047293054570729125,
      "loss": 1.1386,
      "step": 33
    },
    {
      "epoch": 11.333333333333334,
      "grad_norm": 0.06040261685848236,
      "learning_rate": 0.0004459404907880292,
      "loss": 1.1408,
      "step": 34
    },
    {
      "epoch": 11.666666666666666,
      "grad_norm": 0.058981332927942276,
      "learning_rate": 0.00041910900172361764,
      "loss": 1.1394,
      "step": 35
    },
    {
      "epoch": 12.0,
      "grad_norm": 0.058561719954013824,
      "learning_rate": 0.00039251477989448797,
      "loss": 1.1338,
      "step": 36
    },
    {
      "epoch": 12.333333333333334,
      "grad_norm": 0.05893522500991821,
      "learning_rate": 0.0003662358307353897,
      "loss": 1.1345,
      "step": 37
    },
    {
      "epoch": 12.666666666666666,
      "grad_norm": 0.059391047805547714,
      "learning_rate": 0.0003403492349320101,
      "loss": 1.1365,
      "step": 38
    },
    {
      "epoch": 13.0,
      "grad_norm": 0.06054394692182541,
      "learning_rate": 0.0003149309223300428,
      "loss": 1.1395,
      "step": 39
    },
    {
      "epoch": 13.333333333333334,
      "grad_norm": 0.059702951461076736,
      "learning_rate": 0.0002900554492198677,
      "loss": 1.1404,
      "step": 40
    },
    {
      "epoch": 13.666666666666666,
      "grad_norm": 0.059421416372060776,
      "learning_rate": 0.000265795779650105,
      "loss": 1.1344,
      "step": 41
    },
    {
      "epoch": 14.0,
      "grad_norm": 0.05969032645225525,
      "learning_rate": 0.00024222307141148907,
      "loss": 1.136,
      "step": 42
    },
    {
      "epoch": 14.333333333333334,
      "grad_norm": 0.058613862842321396,
      "learning_rate": 0.00021940646731880887,
      "loss": 1.1312,
      "step": 43
    },
    {
      "epoch": 14.666666666666666,
      "grad_norm": 0.05888742208480835,
      "learning_rate": 0.00019741289240311755,
      "loss": 1.1369,
      "step": 44
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.058590032160282135,
      "learning_rate": 0.00017630685760908622,
      "loss": 1.1259,
      "step": 45
    },
    {
      "epoch": 15.333333333333334,
      "grad_norm": 0.05924549326300621,
      "learning_rate": 0.00015615027057328828,
      "loss": 1.1289,
      "step": 46
    },
    {
      "epoch": 15.666666666666666,
      "grad_norm": 0.05917702615261078,
      "learning_rate": 0.00013700225403843468,
      "loss": 1.1309,
      "step": 47
    },
    {
      "epoch": 16.0,
      "grad_norm": 0.058962929993867874,
      "learning_rate": 0.00011891897243618183,
      "loss": 1.1307,
      "step": 48
    },
    {
      "epoch": 16.333333333333332,
      "grad_norm": 0.06021841987967491,
      "learning_rate": 0.00010195346714717812,
      "loss": 1.1238,
      "step": 49
    },
    {
      "epoch": 16.666666666666668,
      "grad_norm": 0.058738309890031815,
      "learning_rate": 8.615550092155477e-05,
      "loss": 1.1271,
      "step": 50
    },
    {
      "epoch": 17.0,
      "grad_norm": 0.05929683893918991,
      "learning_rate": 7.157141191620547e-05,
      "loss": 1.1301,
      "step": 51
    },
    {
      "epoch": 17.333333333333332,
      "grad_norm": 0.058789968490600586,
      "learning_rate": 5.8243977776988585e-05,
      "loss": 1.1308,
      "step": 52
    },
    {
      "epoch": 17.666666666666668,
      "grad_norm": 0.059426240622997284,
      "learning_rate": 4.621229016452155e-05,
      "loss": 1.1254,
      "step": 53
    },
    {
      "epoch": 18.0,
      "grad_norm": 0.05866977572441101,
      "learning_rate": 3.551164009160429e-05,
      "loss": 1.1271,
      "step": 54
    },
    {
      "epoch": 18.333333333333332,
      "grad_norm": 0.059202536940574646,
      "learning_rate": 2.617341440859883e-05,
      "loss": 1.1233,
      "step": 55
    },
    {
      "epoch": 18.666666666666668,
      "grad_norm": 0.058789514005184174,
      "learning_rate": 1.8225003740388545e-05,
      "loss": 1.1278,
      "step": 56
    },
    {
      "epoch": 19.0,
      "grad_norm": 0.05986691638827324,
      "learning_rate": 1.1689722144956671e-05,
      "loss": 1.1325,
      "step": 57
    },
    {
      "epoch": 19.333333333333332,
      "grad_norm": 0.05917408689856529,
      "learning_rate": 6.58673872923693e-06,
      "loss": 1.1255,
      "step": 58
    },
    {
      "epoch": 19.666666666666668,
      "grad_norm": 0.05924156680703163,
      "learning_rate": 2.9310214228202015e-06,
      "loss": 1.1318,
      "step": 59
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.05929377302527428,
      "learning_rate": 7.332930744380905e-07,
      "loss": 1.1298,
      "step": 60
    }
  ],
  "logging_steps": 1.0,
  "max_steps": 60,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 20,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2048,
  "trial_name": null,
  "trial_params": null
}
